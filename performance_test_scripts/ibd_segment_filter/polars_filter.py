from typing import Callable
import polars as pl
from collections import namedtuple
from xopen import xopen
from itertools import chain, combinations
from pathlib import Path
import argparse

Genes = namedtuple("Genes", ["chromosome", "start", "end"])


def load_drive_data(
    drive_results_filepath: Path,
    network_id: str = "",
    pval_threshold: float = None,
    pval_col: str = "",
) -> dict[str, str]:
    """read in the DRIVE results. Filter the networks if the user has
    passed arguments to retrict which networks will be used in the
    analysis

    Parameters
    ----------
    drive_results_filepath : Path
        filepath to a tab separated file generated by the DRIVE cluster
        analysis.

    network_id : str
        ID of a clst in the DRIVE file. We will only return ids for this
        network if the user wishes to filter the data to a specific network.
        There is an assumption that network_id will not be passed to the
        function if pval_threshold is

    pval_threshold : float
        significant threshold that the user can provide. If provided,
        DRIVE will only read in the programs that passed this significance
        threshold. There is an assumption that pval_threshold will not be
        passed to this function if network_id is

    pval_col : str
        column that contains the p-values for each network

    Returns
    -------
    dict[str, str]
        dictionary where the keys are pair ids (Ex: pair1:pair2) and the
        values are the network id they are in

    Raises
    ------
    ValueError
        raises a ValueError if the program can't find the ClstID column or
        the pval_col in the header of the DRIVE file.
    """
    assert (
        not network_id and not pval_threshold
    ), "Values were provided for both the network_id and the pvalue_threshold. Please only provide 1 value"

    return_dict = {}

    with xopen(drive_results_filepath, "r") as results_input:
        header_line = results_input.readline()
        # We need to make sure that certain conditions are met in the
        # header line
        if (
            "clstID" not in header_line
            or pval_col not in header_line
            or "ID.haplotype" not in header_line
        ):
            print(
                f"The header line does not contain the values that we expected in the file indicating a typo, or the file has either been changed since DRIVE has run, or the file is corrupted. Please verify that the file has the columns, clstID, ID.haplotype, and {pval_col}."
            )
            raise ValueError(
                f"Malformed DRIVE file. Ensure the columns, clstID, ID.haplotype, and {pval_col} are in the file"
            )
        # Pull out the indices that we will need from the header
        split_header = header_line.strip().split("\t")

        clstid_col_indx = split_header.index("clstID")
        pval_col_indx = split_header.index(pval_col)
        haplotype_col_indx = split_header.index("ID.haplotype")

        for line in results_input:
            split_line = line.strip().split("\t")
            clst_id = split_line[clstid_col_indx]
            # We are going to make 2 cases to check the network id or the
            # pvalue threshold. In both cases, we check to see if our
            # comparision term (network_id or pval_threshold) is not None. If
            # it is none then python is smart enough to stop the if statement
            # without evaluating the rest and the code will not break
            if network_id and split_line[clstid_col_indx] != network_id:
                continue
            if pval_threshold and split_line[pval_col_indx] > pval_threshold:
                continue
            # making it here means we either short circuited the if statement
            # or we failed the negative checks
            haplotype_ids = split_line[haplotype_col_indx].split(",")

            haplotype_pairs = chain(
                map(
                    lambda pair_combo: ":".join(pair_combo),
                    combinations(haplotype_ids, 2),
                )
            )

            for value in haplotype_pairs:
                return_dict.update({value: clst_id})

    return return_dict


class filter_obj:

    def __init__(
        self, indices: dict[str, str], target_gene: Genes, filter_type: str
    ) -> None:
        self.indices = indices
        self.target_gene = target_gene
        self.filter: Callable = self.set_filter(filter_type)

    def contains(self, data_chunk: pl.LazyFrame, min_cm: float) -> pl.LazyFrame:
        """
        This method works for both DataFrame (eager) and LazyFrame (lazy).
        When passed a LazyFrame, it adds a filter node to the query plan.
        """
        start_col = pl.col(self.indices["str_indx"])
        end_col = pl.col(self.indices["end_indx"])
        cm_col = pl.col(self.indices["cM_indx"])

        exp = (
            (start_col <= self.target_gene.start)
            & (end_col >= self.target_gene.end)
            & (cm_col >= min_cm)
        )
        return data_chunk.filter(exp)

    def overlaps_filter(self, data_chunk: pl.LazyFrame, min_cm: float) -> pl.LazyFrame:
        """Method that will filter the ibd file on four conditions: Chromosome number is the same, segment start position is <= target start position, segment end position is >= to the start position, and the size of the segment is >= to the minimum centimorgan threshold.

        Parameters
        ----------
        data_chunk : pl.DataFrame
            chunk of the ibdfile. The size of this chunk is
            determined by the chunksize argument to
            pd.read_csv. This value is currently set to 100,000.

        min_cm : int
            centimorgan threshold

        Returns
        -------
        pd.DataFrame
            returns the filtered dataframe

        Raises
        ------
        ValueError
            raises a ValueError if the target chromosome number is not
            found within the provided IBD file. This situation will
            lead to a error later in the program which is why the
            exception is raised. It is assumed to be due the user
            providing the incorrect file by accident
        """  # noqa: E501

        # Polars lazy filtering using column expressions and dictionary access
        start_col = pl.col(self.indices["str_indx"])
        end_col = pl.col(self.indices["end_indx"])
        cm_col = pl.col(self.indices["cM_indx"])

        expr = (
            (
                (start_col <= int(self.target_gene.start))
                & (end_col >= int(self.target_gene.start))
            )
            | (
                (start_col >= int(self.target_gene.start))
                & (end_col <= int(self.target_gene.end))
            )
            | (
                (start_col <= int(self.target_gene.end))
                & (end_col >= int(self.target_gene.end))
            )
        ) & (cm_col >= min_cm)

        return data_chunk.filter(expr)

    def set_filter(self, filter_options: str) -> Callable:
        """Method that will set the filter type for the filtering object

        Parameters
        ----------
        filter_options : str
            string that indicates which type of filtering to use.
            Options are 'contains' or 'overlaps'. We know for certain that this value should be either

        Raises
        ------
        ValueError
            raises a ValueError if the user provides an invalid filter
            option
        """
        assert filter_options in {
            "contains",
            "overlaps",
        }, "The filter option provided is invalid. Valid options are 'contains' or 'overlaps'. This error indicates that the argument validation in the parser is not working correctly or the program has been updated with additional filter types and this code was not updated accordingly"

        filters = {"contains": self.contains, "overlaps": self.overlaps_filter}

        return filters[filter_options]


def filter_ibd_segments_new(ibd_segment_file: Path, drive_results: Path, filter_type: str, target_gene: Genes) -> None:
    """main function that will used for testing the polars filtering"""

    drive_network_mapping = load_drive_data(drive_results)

    indices = {
        "id1_indx": "column_1",
        "hap1_indx": "column_2",
        "id2_indx": "column_3",
        "hap2_indx": "column_4",
        "chr_indx": "column_5",
        "str_indx": "column_6",
        "end_indx": "column_7",
        "cM_indx": "column_8",
    }

    filter_cls = filter_obj(
        indices=indices,
        target_gene=target_gene,
        filter_type=filter_type,
    )

    df = (
        pl.scan_csv(
            ibd_segment_file,
            has_header=False,
            separator="\t",
            schema_overrides={
                "column_1": str,
                "column_2": str,
                "column_3": str,
                "column_4": str,
            },
        )
        .pipe(filter_cls.filter, min_cm=2.1)
        .with_columns(
            (
                pl.col("column_1")
                + "."
                + pl.col("column_2")
                + ":"
                + pl.col("column_3")
                + "."
                + pl.col("column_4")
            )
            .replace_strict(drive_network_mapping, default=None)
            .alias("pair")
        )
        .drop_nulls()
        .collect()
    )

    print(df)
    
if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--ibd-file",
        type=Path,
        required=True,
        help="Path to an ibd file from hap-IBD"
    )

    parser.add_argument(
        "--drive-results",
        reqired=True,
        type=Path,
        help="output file from running the clustering step of DRIVE"
    )

    parser.add_argument(
        "--min-cm",
        type=float,
        default=3.0,
        help="minimum centimorgan threshold that will be used to filter the IBD segments"
    )

    parser.add_argument(
        "--format",
        "-f",
        default="hapibd",
        type=str,
        help="IBD program used to detect segments. Allowed values are hapibd, ilash, germline, rapid. Program expects for value to be lowercase. (default: %(default)s)",
        choices=["hapibd", "ilash", "germline", "rapid"],
    )

    parser.add_argument(
        "--target",
        "-t",
        type=str,
        help="Target region or position, chr:start-end or chr:pos. this argument will be used to filter the pairwise segments down to just a region that the user is interested in",
        required=True,
    )

    args = parser.parse_args()