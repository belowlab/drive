{"0": {
    "doc": "Changelog",
    "title": "Changelog",
    "content": ". ",
    "url": "/changelog.html",
    
    "relUrl": "/changelog.html"
  },"1": {
    "doc": "Docker Installation",
    "title": "Docker Installation",
    "content": "Coming soon . ",
    "url": "/documentation/docker.html",
    
    "relUrl": "/documentation/docker.html"
  },"2": {
    "doc": "Github Installation",
    "title": "Using Github to install DRIVE:",
    "content": ". This installation method assumes that you are familiar with Git and Github, the commandline, and python’s Anaconda package manager and that these programs are installed/can be install on whatever computing environment you are using. You will have to use all of these tools so you will need to be familiar enough with each one to run the example commands. If you wish to read the documentation for each of these then they will be listed below: . | Git: Git Website . | Github: Github Website . | Commandline Interface: This is probably overkill but here is a very indepth CLI tutorial . | Anaconda Anaconda Website . | . Optional Installation Dependency: You can also use Poetry to install the program. Poetry is a python package manager (another alternative to Pip and Conda and all the other package manages) that has good dependency resolution to create a reproducible environment. You can read more about the project here Poetry documentation and the steps to install it are described here Poetry Installation. For individuals wishing to contribute to DRIVE development, Poetry is the current recommended way to install DRIVE. Poetry allows for individuals to install the necessary development dependencies to properly format and commit the code so that they can contribute to the repository. ",
    "url": "/documentation/github.html#using-github-to-install-drive",
    
    "relUrl": "/documentation/github.html#using-github-to-install-drive"
  },"3": {
    "doc": "Github Installation",
    "title": "Steps to installing DRIVE:",
    "content": "Step 1: Clone the Github repository: . You can clone the Github repository into your local environment using the command shown below: . git clone https://github.com/belowlab/drive.git . You should now have a directory called drive. You can check if this exists using the command: . ls drive/ . The process should look similar to the screencasts below: . If you see a directory file tree then the program cloned correctly. If you receive an error saying that the directory does not exist, then you will have to debug the error to move onto step 2. Step 2: Installing necessary dependencies: . if not using Poetry or are not interested in developing the project: If you are not using Poetry than you can directly clone the conda environment.yml file using the following command: . conda env create -f DRIVE_envi.yml . Make sure that you are in the drive directory. This command will create a virtual environment called DRIVE using python 3.6 with all the required dependencies. If using Poetry: If you are using poetry you will first have to create a new conda environment or virtual environment using venv and then activate the environment. DRIVE has only been tested with python &gt;= 3.6 and python &lt;= 3.9. Other version of python may not work. For this reason it is currently recommended to specify the python version within this range. Once you have created and activated the environment, you can install the necessary dependencies using the following command: . poetry install --without dev . This command will install all of the runtime dependencies and not the developer dependencies. If you are developing the tool then you can use the command . poetry install --with dev . If successful you will have all the dependencies you need to run the program. You can check this by running the command: . python drive/drive.py -h . you should see the DRIVE cli as shown below: . ",
    "url": "/documentation/github.html#steps-to-installing-drive",
    
    "relUrl": "/documentation/github.html#steps-to-installing-drive"
  },"4": {
    "doc": "Github Installation",
    "title": "Github Installation",
    "content": " ",
    "url": "/documentation/github.html",
    
    "relUrl": "/documentation/github.html"
  },"5": {
    "doc": "Home",
    "title": "Welcome to the DRIVE Documentation!",
    "content": ". DRIVE (v1.0.0) is a C.L.I. tool (finish description) . ",
    "url": "/#welcome-to-the-drive-documentation",
    
    "relUrl": "/#welcome-to-the-drive-documentation"
  },"6": {
    "doc": "Home",
    "title": "Contact:",
    "content": ". If you have any questions about DRIVE, you can either post an issue on the Github issues page or you can contact us at the email address, insert email here. ",
    "url": "/#contact",
    
    "relUrl": "/#contact"
  },"7": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "/",
    
    "relUrl": "/"
  },"8": {
    "doc": "Documentation",
    "title": "Documentation",
    "content": "The links below have information about how to install the program and how to run the program . ",
    "url": "/documentation/",
    
    "relUrl": "/documentation/"
  },"9": {
    "doc": "Example Scripts",
    "title": "Example command to run IBDCluster/DRIVE:",
    "content": ". {drive_file_path} -o {output_dir} -f {IBD_filepath} --gene-position {gene-position} -n {gene_name} --cM {centimorgan_threshold} --log-to-console --log-filename {output-log-filepath} -c {carrier_filepath} . The above command assumes that you have installed the program and changed the IBDCluster.py file to an executable program. ",
    "url": "/examples/#example-command-to-run-ibdclusterdrive",
    
    "relUrl": "/examples/#example-command-to-run-ibdclusterdrive"
  },"10": {
    "doc": "Example Scripts",
    "title": "Example Scripts",
    "content": "The links below give examples of how to use the program. ",
    "url": "/examples/",
    
    "relUrl": "/examples/"
  },"11": {
    "doc": "Inputs",
    "title": "Inputs:",
    "content": ". The DRIVE program has several command line arguments shown in the image below. Required Inputs: . | ibd file: This input file is the result of running hap-IBD to determine pairwise IBD sharing between individuals in a BioBank. This file has to be formed before because IBDCluster does not determine pairwise ibd sharing. The table below shows the format of the file (The file doesn’t have a header line but I have added one to the table for ease of explaining the file). | . | Pair 1 ID | Pair 1 Phase | Pair 2 ID | Pair 2 Phase | Chromosome | Segment Start Pos | Segment End Pos | Segment Length (cM) | . | ID1 | Phase 1 | ID2 | Phase 2 | Chromosome # | Segment start base position | Segment end base position | Segment length | . There should be a total of eight columns that are all tab separated. The file should have information about each individual in the pair and the haplotype phase for each variant, the chromosome that the segment is on, the location of the segment, and the length of the segment. All of this information will be used by the program so it is mandatory. This file will be supplied through the –ibd-file or -f flag. It is a required file. | Gene name: This argument is the name of the locus of interest. If the locus is a gene then it can be that name (Ex: CFTR). The user can provide any value they want to here. The gene name is used to name output files but is not used in other parts of the program. | . | Gene position: This argument is the locus of interest. It is represented by X:start-end, where X is the chromosome number and start and end refer to the start and end points of the locus in base pairs. The program will exit early if this value is improperly formatted. | . Warning about the gene position: Make sure that the base position in the file corresponds to the same build of the human genome as what you used in the IBD detection software. If the builds are different then you will get inaccurate results. | carrier file: This input file is a tab separated text file that indicates which individuals are affected by the phenotypes of interest. The first column is expected to be titled “grids”. Every other column after this should be either a 0 or 1 for each sphenotype of interest. Currently this program only supports binary phenotypes. An example of this format is shown below. | . | grids | Phenotype A | Phenotype B | . | grid 1 | 1 | 0 | . | grid 2 | 0 | 1 | . | grid 3 | 0 | 0 | . This required input file will be supplied to the –carriers or -c flag. Some people may be familiar with a PheCode matrix, and thats all this file really is. You’re not restricted to only using PheCodes though. Any phenotype will work for this program as long as you can use binary phenotyping to determine cases and controls. Optional Dependencies: . | .env file: This input file is just a environment file that has two variables “HAPIBD_PATH” and “JSON_PATH”. The HAPIBD_PATH variable has the directory where the ibd files are. The suffix of the file has to be .env. This file will be supplied through the –env or the -e argument. This file is required by the program but the the program comes with a default file within the install directory so you do not have to supply an argument unless you are using a custom .env file. | . | config.json: This input file is a json file that has information about the plugins that are going to be used in the analysis. The default config.json for the stock plugins are shown below. | . { \"plugins\":[\"plugins.pvalues\", \"plugins.network_writer\", \"plugins.allpair_writer\"], \"modules\": [ { \"name\":\"pvalues\" }, { \"name\": \"network_writer\" }, { \"name\": \"allpair_writer\" } ] } . The json files should have the keys “plugins” and “modules”. The value for the “plugins” key is a list of strings that have the module path of the plugin. To break this down each plugin is located in the plugins module in the IBDCluster plugin, therefore the first part of the module path in the default config.json is “plugins”. The name of the plugin .py file is the second part of the module path. For example there is a default plugin pvalues.py within the plugin directory, therefore the module path is “plugins.pvalues”. This structure of the plugins directory is explained in more detail within the section called “Stock Plugins”. The value for the “modules” key is a list of key, value pairs where the key is “name” and the value is the name of the plugin which can be found in the initialize function in the plugin .py file (This is also described in more detail in the “Stock Plugins” section). This file will be supplied through the optional –json-config or the -j flag. There is a default config file that IBDCluster reads from but you can provide your own config file if you wish to turn on or off a plugin or if you wish to use a custom plugin (This process will be described in the “Custom Plugin Design” section). | sliding window: This argument indicates if the user wishes to use a sliding window of 1MB across the region of interest. Test runs of large loci (Multiple MBs) have shown that the program can identify excessively large clusters. This can be alleviate using this sliding window. All the user has to pass is an argument that “–sliding-window” | . ",
    "url": "/documentation/inputs.html#inputs",
    
    "relUrl": "/documentation/inputs.html#inputs"
  },"12": {
    "doc": "Inputs",
    "title": "Inputs",
    "content": " ",
    "url": "/documentation/inputs.html",
    
    "relUrl": "/documentation/inputs.html"
  },"13": {
    "doc": "Installation",
    "title": "Installing DRIVE:",
    "content": "This program can be installed through several different options which are listed below. For users of the software, the recommended approach is through the pip install. For developers the recommended approach is the Github installation. Click on the links to find out more information. ",
    "url": "/documentation/installation.html#installing-drive",
    
    "relUrl": "/documentation/installation.html#installing-drive"
  },"14": {
    "doc": "Installation",
    "title": "Installation",
    "content": " ",
    "url": "/documentation/installation.html",
    
    "relUrl": "/documentation/installation.html"
  },"15": {
    "doc": "Outputs",
    "title": "Output Files:",
    "content": ". IBDCluster produces three files using the stock plugins. The Networks file and the Allpairs file will be in a subdirectory that is named for whatever Gene you are interested in. This subdirectory will be in the user specified output directory. The phenotype prevalence file will be in the main output directory. Networks.txt File: . The first file is the *networks.txt file. This file gives information on a per network level. Each row is a different network identified in the analysis. There are 11 columns that will be in each file. These first 11 columns are shown below in the table and then they are described below. | program | gene | network_id | chromosome | IIDs_count | haplotypes_count | IIDs | haplotypes | min_pvalue | min_pvalue_phecode | min_phecode_desc | . | hapibd | gene name | # | # | # | # | grids in network | haplotypes in network | # | phecode label | description of phecode | . | program: This will have the name of the IBD program that was used to identify the IBD segments. This value currently will be hapibd because it is the only supported program. | gene: This value will be the gene that you are interested in for the analysis. | network_id: This is the number of the network. | chromosome: This is the chromosome number that the gene is on. | IIDs_count: This is the number of different individuals in the network. This number does not take into account haplotypes. | haplotypes_count: This is the number of haplotypes in the network. This value will not be higher than the IIDs_count but could be lower if there is inbreeding in the population. | IIDs: This value is a list of the individual IDs in the network. | haplotypes: This value is a list of the haplotypes in the network. Each haplotype consider of the individual ID concatenated with the phase number. | min_pvalue: This value is the lowest pvalue found during the binomial test. | min_pvalue_phecode: This value is the PheCode label for that corresponds to the lowest pvalue. | min_phecode_desc: This value is the description of the PheCode that corresponds to the lowest pvalue. | . Every other column in the file depends on what phenotypes the user supplies. For each phenotype provided, two columns will be formed: a pvalue columns and an ind_in_network columns. The pvalue column will have the pvalue calculated during the binomial test and the ind_in_network columns will have the number of individuals in the network affected by the phenotype. Allpairs.txt File: . The second file produced will an *allpairs.txt file. This file gives information about the segment shared between each pair in a network. There are eleven columns shown in the table below and then each column is described in more detail after the table. | program | network_id | pair_1 | pair_2 | phase_1 | phase_2 | chromosome | gene_name | start | end | length | . | hapibd | 1 | grid 1 | grid 2 | id1 with phase | id2 with phase | 1 | name | start position | end position | length of segment | . | program: This will have the name of the IBD program that was used to identify the IBD segments. This value currently will be hapibd because it is the only supported program. | network_id: This value has the network number that the pair is in. This value starts at one and goes to how ever many networks were identified . | pair_1: This value will have the id of the first individual in the pair. | pair_2: This value will have the id of the second individual in the pair . | phase_1: This value will have the haplotype phase for the first individual in the pair. This value will be the pair_1 id plus the haplotype number attached to it (This value is 1 or 2 for hapibd). An example of this is R12341234.1 . | phase_2: This value will have the haplotype phase for the second individual. It follows the same format as the phase_1 value . | chromosome: This value has the chromosome number that the gene of interest is on . | gene_name: This value has the gene name of interest . | start: This value is an integer that has the start base position of the gene. You can use gnomAD to find this, just make sure that the build matches what was providied to hap-IBD to identify segments. | end: This value is an integer that has the end base position of the gene. This value can also be found using gnomAD, just again be aware of the genome build. | length: This value will be an integer that has the total length of the segment in cM. | . Log File: . The program also produces a log file in whatever directory the specified as output. This file is called “IBDCluster.log” by default. It will contain all of the parameters passed to the program and it will have all of the logging messages for whatever log level the user supplied. ",
    "url": "/documentation/outputs.html#output-files",
    
    "relUrl": "/documentation/outputs.html#output-files"
  },"16": {
    "doc": "Outputs",
    "title": "Outputs",
    "content": " ",
    "url": "/documentation/outputs.html",
    
    "relUrl": "/documentation/outputs.html"
  },"17": {
    "doc": "Pip Installation",
    "title": "Using Pip to install IBDCluster:",
    "content": ". DRIVE v1.0.0 has been official released on PYPI (DRIVE pypi page)! The software can be installed using the following command: . pip install drive-ibd . Warning about supported python versions: DRIVE has only been tested with python &gt;= 3.6.13 and python &lt;= 3.9. These are currently the only supported python versions. The recommend way to install DRIVE using pip would be to either create a virtual environment using Anaconda or venv. Once you activate the virtual environment then you can use the above pip command to install DRIVE into an isolated environment. ",
    "url": "/documentation/pip.html#using-pip-to-install-ibdcluster",
    
    "relUrl": "/documentation/pip.html#using-pip-to-install-ibdcluster"
  },"18": {
    "doc": "Pip Installation",
    "title": "Pip Installation",
    "content": " ",
    "url": "/documentation/pip.html",
    
    "relUrl": "/documentation/pip.html"
  }
}
