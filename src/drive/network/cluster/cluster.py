from datetime import datetime
import logging

from igraph import Graph, VertexClustering
from drive.models.types import ClusterConfig, NetworkCandidate
from log import CustomLogger
from pandas import DataFrame
from drive.network.models import Network, Network_Interface
from drive.network.graph import (
    generate_graph,
    random_walk,
    get_network_haplotypes_and_members,
    gather_members,
    get_cluster_metrics,
    hub_detection,
)

# creating a logger
logger: logging.Logger = CustomLogger.get_logger(__name__)


def filter_cluster_size(
    random_walk_clusters_sizes: list[int], min_cluster_size: int
) -> list[int]:
    """Method to filter networks that are smaller than the
    min_cluster_size from the analysis

    Parameters
    ----------
    random_walk_clusters_sizes : list[int]
        size of each cluster from the random walk results

    min_cluster_size : int
        threshold for the minimum sized network in the analysis

    Returns
    -------
    list[int]
        returns a list of integers where each integer
        represents a cluster id. Each cluster in the
        network will be >= to the min_cluster_size
        attribute.
    """
    return [
        i for i, v in enumerate(random_walk_clusters_sizes) if v >= min_cluster_size
    ]


def evaluate_clusters(
    graph: Graph,
    cluster_ids: list[int],
    random_walk_clusters: VertexClustering,
    config: ClusterConfig,
    haplotype_mapping: dict[int, str],
    parent_cluster_id: str | float | None = None,
    current_recheck_count: int = 0,
) -> tuple[list[Network], list[NetworkCandidate]]:
    """Method for getting the information about membership,
    true positive, false positives, etc... from the random
    walk

    Parameters
    ----------
    graph : ig.Graph
        Graph object generated by ig.Graph.DataFrame

    cluster_ids : List[int]
        list of integers for each cluster id

    random_walk_clusters : ig.VertexClustering
        result from performing the random walk.

    config : ClusterConfig
        Configuration object containing thresholds and parameters
        passed by the user

    haplotype_mapping : dict[int, str]
        mapping of integer ids to haplotype strings

    parent_cluster_id : Optional[str]
        id of the original cluster that is now being broken up. Child
        cluster ids will take the form parent_id.child_id

    current_recheck_count : int
        current number of times the network has been reclustered

    Returns
    -------
    tuple[List[Network], List[NetworkCandidate]]
        returns a tuple containing the list of final clusters and the
        list of clusters that need to be rechecked
    """
    # These are the list of that will contain the final clusters
    final_clusters: list[Network] = []
    recheck_clusters: list[NetworkCandidate] = []

    for clst_id in cluster_ids:
        # We need to form the appropriate id if the cluster has a
        # parent otherwise they get the value of the clst_id argument
        if parent_cluster_id:
            clst_name = f"{parent_cluster_id}.{clst_id}"
        else:
            clst_name = f"{clst_id}"

        # We are going to get the vertex id and member id of each
        # graph
        member_list, vertex_ids = gather_members(
            random_walk_clusters.membership, clst_id, graph
        )

        cluster_metrics = get_cluster_metrics(
            graph, clst_id, member_list, random_walk_clusters, vertex_ids
        )

        too_sparse = cluster_metrics.tp_ratio < config.min_connected_threshold

        too_big = len(member_list) > config.max_network_size

        # If the graph is too sparse and it is too large and the max
        # number of rechecks has not been reached then we will put
        # the network into a recluster dictionary. Otherwise it is
        # added to the final_clst list

        if (
            current_recheck_count < config.max_recheck_count
            and too_sparse
            and too_big
            and config.recluster
        ):
            # We can put all of this information into a NetworkCandidate
            # class. Here the member list will still be in integers
            candidate = NetworkCandidate(
                member_ids=member_list,
                curr_iteration=current_recheck_count,
                candidate_id=clst_name,
                candidate_metrics=cluster_metrics,
            )
            # debug statement if we want to see the members and the haplotypes
            logger.debug(f"members: {member_list}\nhaplotypes: {vertex_ids}")

            recheck_clusters.append(candidate)

        else:
            # we need to convert the integer ids back to strings
            haplotype_ids, member_ids = get_network_haplotypes_and_members(
                member_list, haplotype_mapping
            )

            network = Network(
                clst_name,
                cluster_metrics.tp_count,
                cluster_metrics.tp_ratio,
                # [],  # fp_list - empty to save memory
                cluster_metrics.fp_count,
                member_ids,
                haplotype_ids,
            )
            # logger.info(f"members: {member_ids}\nhaplotypes: {haplotype_ids}")

            final_clusters.append(network)

    return final_clusters, recheck_clusters


ReclusterResponse = tuple[Graph, VertexClustering] | None


def recluster_candidate(
    network_candidate: NetworkCandidate,
    ibd_pd: DataFrame,
    ibd_vs: DataFrame,
    config: ClusterConfig,
) -> ReclusterResponse:
    """Method that will redo the clustering, if the
    networks were too large or did not show a high degree
    of connectedness

    Parameters
    ----------
    network : Network_Interface
        object that represents each cluster. These objects have information
        about the cluster id, number and ratio of edges, true_positive_percent,
        false_negative_edges, false_negative_count

    ibd_pd : pd.DataFrame
        DataFrame that has information about the edges that a pair shares

    Returns
    -------
    ReclusterResponse
        returns the reclustered graph and clusters identified by the
        random walk.
    """
    # filters for the specific cluster
    redopd = ibd_pd.loc[
        (ibd_pd["idnum1"].isin(network_candidate.member_ids))
        & (ibd_pd["idnum2"].isin(network_candidate.member_ids))
    ]

    redo_vs = ibd_vs.loc[ibd_vs.idnum.isin(network_candidate.member_ids)]

    # If the redopd or redo_vs is empty it causes strange behavior and the code will
    # usually fail. The desired behavior is for the program to tell the user that
    # the graph could not be constructed and then for it to move on.
    if redopd.empty or redo_vs.empty:
        logger.debug(
            f"A graph was not able to be generated when we attempted to recluster the network: {network_candidate.candidate_id}. This error probably indicates that there were none of the {len(network_candidate.member_ids)} individuals in that specific network that shared ibd segments with one another."
        )
        return None
    # We are going to generate a new Networks object using the redo graph
    redo_networks = generate_graph(
        redopd, redo_vs  # pyright: ignore[reportArgumentType]
    )

    # performing the random walk
    redo_walktrap_clusters = random_walk(redo_networks, config)

    # If only one cluster is found then we should attempt the hub
    # detection and pruning step
    if len(redo_walktrap_clusters.sizes()) == 1:
        # creates an empty dataframe with these columns
        rmID = hub_detection(network_candidate.member_ids, redopd, config)
        # refilter the redopd and redo_vs to not include the hub nodes
        redopd = redopd.loc[
            (~redopd["idnum1"].isin(rmID)) & (~redopd["idnum2"].isin(rmID))
        ]

        redo_vs = ibd_vs.loc[~redo_vs["idnum"].isin(rmID)]

        # We are now going to repeat the random walk attempt with the
        # restricted id list after hub nodes are removed
        redo_networks = generate_graph(
            redopd, redo_vs  # pyright: ignore[reportArgumentType]
        )
        redo_walktrap_clusters = random_walk(redo_networks, config)

    return redo_networks, redo_walktrap_clusters


def cluster(
    edge_info_df: DataFrame,
    vertex_info_df: DataFrame,
    haplotype_mappings: dict[int, str],
    config: ClusterConfig,
) -> list[Network_Interface]:
    """Main function that will perform the clustering using igraph

        Parameters
        ----------
        edge_info_df : DataFrame
            pandas dataframe that represents all of the edges in the cohort. The
    dataframe has the columns

        cluster_obj : ClusterHandler
            Object that contains information about how the random walk
            needs to be performed. It will use the construct networks and return those
            values in a list.

        min_network_size : int
            threshold so we can filter networks that are >= the threshold

            Returns
    """
    start_time = datetime.now()

    # Generate the first pass random walk and the initial networks
    network_graph = generate_graph(
        edge_info_df,
        vertex_info_df,
    )

    logger.info(
        f"Identified {network_graph.ecount()} IBD segments from {network_graph.vcount()} haplotypes"  # noqa: E501
    )

    random_walk_results = random_walk(network_graph, config)

    allclst = filter_cluster_size(random_walk_results.sizes(), config.min_cluster_size)

    final_networks, recluster_queue = evaluate_clusters(
        network_graph, allclst, random_walk_results, config, haplotype_mappings, None, 1
    )

    while recluster_queue:
        candidate = recluster_queue.pop(0)

        result = recluster_candidate(candidate, edge_info_df, vertex_info_df, config)

        if result:
            allclst = filter_cluster_size(result[1].sizes(), config.min_cluster_size)

            new_final_clusters, new_candidates = evaluate_clusters(
                result[0],
                allclst,
                result[1],
                config,
                haplotype_mappings,
                candidate.candidate_id,
                candidate.curr_iteration + 1,
            )
            final_networks.extend(new_final_clusters)
            recluster_queue.extend(new_candidates)

        # If the candidate can't be reclustered for whatever reason than it
        # will be converted from NetworkCandidate to Network and added to the
        # final network list
        else:

            haplotype_ids, member_ids = get_network_haplotypes_and_members(
                candidate.member_ids, haplotype_mappings
            )

            network = Network(
                clst_id=candidate.candidate_id,
                true_positive_count=candidate.candidate_metrics.tp_count,
                true_positive_percent=candidate.candidate_metrics.tp_ratio,
                false_negative_count=candidate.candidate_metrics.fp_count,
                members=member_ids,
                haplotypes=haplotype_ids,
            )

            final_networks.append(network)

    logger.info(f"Identified {len(final_networks)} IBD clusters")

    end_time = datetime.now()

    logger.verbose(f"clustering analysis finished. Time taken: {end_time-start_time}")

    return final_networks
